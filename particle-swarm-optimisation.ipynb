{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad310ca",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b90939f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7439ab7",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ee9e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/uci-secom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "527a57eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time        0        1          2          3       4      5  \\\n",
       "0  2008-07-19 11:55:00  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   \n",
       "1  2008-07-19 12:32:00  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0   \n",
       "2  2008-07-19 13:17:00  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   \n",
       "3  2008-07-19 14:43:00  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0   \n",
       "4  2008-07-19 15:22:00  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0   \n",
       "\n",
       "          6       7       8  ...       581     582     583     584      585  \\\n",
       "0   97.6133  0.1242  1.5005  ...       NaN  0.5005  0.0118  0.0035   2.3630   \n",
       "1  102.3433  0.1247  1.4966  ...  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
       "2   95.4878  0.1241  1.4436  ...   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
       "3  104.2367  0.1217  1.4882  ...   73.8432  0.4990  0.0103  0.0025   2.0544   \n",
       "4  100.3967  0.1235  1.5031  ...       NaN  0.4800  0.4766  0.1045  99.3032   \n",
       "\n",
       "      586     587     588       589  Pass/Fail  \n",
       "0     NaN     NaN     NaN       NaN         -1  \n",
       "1  0.0096  0.0201  0.0060  208.2045         -1  \n",
       "2  0.0584  0.0484  0.0148   82.8602          1  \n",
       "3  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "4  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "\n",
       "[5 rows x 592 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18677b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 592)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "971b2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46c23d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3002.910638</td>\n",
       "      <td>2484.700932</td>\n",
       "      <td>2180.887035</td>\n",
       "      <td>1383.901023</td>\n",
       "      <td>4.159516</td>\n",
       "      <td>99.106573</td>\n",
       "      <td>100.209538</td>\n",
       "      <td>0.121122</td>\n",
       "      <td>1.460995</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>...</td>\n",
       "      <td>38.623767</td>\n",
       "      <td>0.499777</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>3.065869</td>\n",
       "      <td>0.021445</td>\n",
       "      <td>0.016464</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>99.606461</td>\n",
       "      <td>-0.867262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>200.204648</td>\n",
       "      <td>184.815753</td>\n",
       "      <td>209.206773</td>\n",
       "      <td>458.937272</td>\n",
       "      <td>56.104457</td>\n",
       "      <td>9.412812</td>\n",
       "      <td>11.363940</td>\n",
       "      <td>0.012831</td>\n",
       "      <td>0.090461</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>...</td>\n",
       "      <td>72.871466</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>3.577730</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>93.895701</td>\n",
       "      <td>0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2965.670000</td>\n",
       "      <td>2451.515000</td>\n",
       "      <td>2180.700000</td>\n",
       "      <td>1080.116050</td>\n",
       "      <td>1.011000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.762200</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>1.410950</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>2.306200</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>44.368600</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3010.920000</td>\n",
       "      <td>2498.910000</td>\n",
       "      <td>2200.955600</td>\n",
       "      <td>1283.436800</td>\n",
       "      <td>1.310100</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>101.492200</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>1.461500</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.757600</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>71.778000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3056.540000</td>\n",
       "      <td>2538.745000</td>\n",
       "      <td>2218.055500</td>\n",
       "      <td>1590.169900</td>\n",
       "      <td>1.518800</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>104.530000</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>1.516850</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>...</td>\n",
       "      <td>57.449750</td>\n",
       "      <td>0.502350</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.294950</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>114.749700</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3356.350000</td>\n",
       "      <td>2846.440000</td>\n",
       "      <td>2315.266700</td>\n",
       "      <td>3715.041700</td>\n",
       "      <td>1114.536600</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>129.252200</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>1.656400</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>...</td>\n",
       "      <td>737.304800</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>99.303200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>737.304800</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000   \n",
       "mean   3002.910638  2484.700932  2180.887035  1383.901023     4.159516   \n",
       "std     200.204648   184.815753   209.206773   458.937272    56.104457   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    2965.670000  2451.515000  2180.700000  1080.116050     1.011000   \n",
       "50%    3010.920000  2498.910000  2200.955600  1283.436800     1.310100   \n",
       "75%    3056.540000  2538.745000  2218.055500  1590.169900     1.518800   \n",
       "max    3356.350000  2846.440000  2315.266700  3715.041700  1114.536600   \n",
       "\n",
       "                 5            6            7            8            9  ...  \\\n",
       "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000  ...   \n",
       "mean     99.106573   100.209538     0.121122     1.460995    -0.000840  ...   \n",
       "std       9.412812    11.363940     0.012831     0.090461     0.015107  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000    -0.053400  ...   \n",
       "25%     100.000000    97.762200     0.121100     1.410950    -0.010800  ...   \n",
       "50%     100.000000   101.492200     0.122400     1.461500    -0.001300  ...   \n",
       "75%     100.000000   104.530000     0.123800     1.516850     0.008400  ...   \n",
       "max     100.000000   129.252200     0.128600     1.656400     0.074900  ...   \n",
       "\n",
       "               581          582          583          584          585  \\\n",
       "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000   \n",
       "mean     38.623767     0.499777     0.015308     0.003844     3.065869   \n",
       "std      72.871466     0.013084     0.017179     0.003721     3.577730   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.497900     0.011600     0.003100     2.306200   \n",
       "50%       0.000000     0.500200     0.013800     0.003600     2.757600   \n",
       "75%      57.449750     0.502350     0.016500     0.004100     3.294950   \n",
       "max     737.304800     0.509800     0.476600     0.104500    99.303200   \n",
       "\n",
       "               586          587          588          589    Pass/Fail  \n",
       "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000  \n",
       "mean      0.021445     0.016464     0.005280    99.606461    -0.867262  \n",
       "std       0.012366     0.008815     0.002869    93.895701     0.498010  \n",
       "min      -0.016900     0.000000     0.000000     0.000000    -1.000000  \n",
       "25%       0.013400     0.010600     0.003300    44.368600    -1.000000  \n",
       "50%       0.020500     0.014800     0.004600    71.778000    -1.000000  \n",
       "75%       0.027600     0.020300     0.006400   114.749700    -1.000000  \n",
       "max       0.102800     0.079900     0.028600   737.304800     1.000000  \n",
       "\n",
       "[8 rows x 591 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d67b987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time         0\n",
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "            ..\n",
       "586          0\n",
       "587          0\n",
       "588          0\n",
       "589          0\n",
       "Pass/Fail    0\n",
       "Length: 592, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f471c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0309300e+03, 2.5640000e+03, 2.1877333e+03, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [3.0957800e+03, 2.4651400e+03, 2.2304222e+03, ..., 2.0100000e-02,\n",
       "        6.0000000e-03, 2.0820450e+02],\n",
       "       [2.9326100e+03, 2.5599400e+03, 2.1864111e+03, ..., 4.8400000e-02,\n",
       "        1.4800000e-02, 8.2860200e+01],\n",
       "       ...,\n",
       "       [2.9788100e+03, 2.3797800e+03, 2.2063000e+03, ..., 8.6000000e-03,\n",
       "        2.5000000e-03, 4.3523100e+01],\n",
       "       [2.8949200e+03, 2.5320100e+03, 2.1770333e+03, ..., 2.4500000e-02,\n",
       "        7.5000000e-03, 9.3494100e+01],\n",
       "       [2.9449200e+03, 2.4507600e+03, 2.1954444e+03, ..., 1.6200000e-02,\n",
       "        4.5000000e-03, 1.3778440e+02]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature variables\n",
    "X = data.drop(['Time','Pass/Fail'], axis=1).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f114bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, ..., -1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target variable\n",
    "y = data['Pass/Fail'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3712449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d400945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4558275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1567, 590)\n",
      "Shape of y_train: (1567,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X.shape)\n",
    "print(\"Shape of y_train:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ad89af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "LogisticRegression()\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18af6893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c90934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8630573248407644"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f41cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error rate\n",
    "def error_rate(xtrain, ytrain, x, opts):\n",
    "    # parameters\n",
    "    fold = opts['fold']\n",
    "    xt = fold['xt']\n",
    "    yt = fold['yt']\n",
    "    xv = fold['xv']\n",
    "    yv = fold['yv']\n",
    "    # number of instances\n",
    "    num_train = np.size(xt, 0)\n",
    "    num_valid = np.size(xv, 0)\n",
    "    # Define selected features\n",
    "    xtrain = xt[:, x == 1]\n",
    "    ytrain = yt.reshape(num_train)\n",
    "    xvalid = xv[:, x == 1]\n",
    "    yvalid = yv.reshape(num_valid)\n",
    "    # Training\n",
    "    mdl     = LinearRegression()\n",
    "    mdl.fit(xtrain, ytrain)\n",
    "    # Prediction\n",
    "    ypred   = mdl.predict(xvalid)\n",
    "    error   = mean_squared_error(yvalid, ypred, squared=False)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc152051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rate & Feature size\n",
    "def Fun(xtrain, ytrain, x, opts):\n",
    "    # parameters\n",
    "    alpha = 0.99\n",
    "    beta = 1 - alpha\n",
    "    # original feature size\n",
    "    max_feat = len(x)\n",
    "    # Number of selected features\n",
    "    num_feat = np.sum(x == 1)\n",
    "    # Solve if no feature selected\n",
    "    if num_feat == 0:\n",
    "        cost = 1\n",
    "    else:\n",
    "        # Get error rate\n",
    "        error = error_rate(xtrain, ytrain, x, opts)\n",
    "        # Objective function\n",
    "        cost = alpha * error + beta * (num_feat / max_feat)\n",
    "        \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "923dba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_position(lb, ub, N, dim):\n",
    "    X = np.zeros([N, dim], dtype='float')\n",
    "    for i in range(N):\n",
    "        for d in range(dim):\n",
    "            X[i,d] = lb[0,d] + (ub[0,d] - lb[0,d]) * random.random()        \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e011469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_velocity(lb, ub, N, dim):\n",
    "    V    = np.zeros([N, dim], dtype='float')\n",
    "    Vmax = np.zeros([1, dim], dtype='float')\n",
    "    Vmin = np.zeros([1, dim], dtype='float')\n",
    "    # Maximum & minimum velocity\n",
    "    for d in range(dim):\n",
    "        Vmax[0,d] = (ub[0,d] - lb[0,d]) / 2\n",
    "        Vmin[0,d] = -Vmax[0,d]\n",
    "        \n",
    "    for i in range(N):\n",
    "        for d in range(dim):\n",
    "            V[i,d] = Vmin[0,d] + (Vmax[0,d] - Vmin[0,d]) * random.random()\n",
    "        \n",
    "    return V, Vmax, Vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4998211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_conversion(X, thres, N, dim):\n",
    "    Xbin = np.zeros([N, dim], dtype='int')\n",
    "    for i in range(N):\n",
    "        for d in range(dim):\n",
    "            if X[i,d] > thres:\n",
    "                Xbin[i,d] = 1\n",
    "            else:\n",
    "                Xbin[i,d] = 0\n",
    "    \n",
    "    return Xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f740f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary(x, lb, ub):\n",
    "    if x < lb:\n",
    "        x = lb\n",
    "    if x > ub:\n",
    "        x = ub\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccd2c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jfs(xtrain, ytrain, opts):\n",
    "    # Parameters\n",
    "    ub    = 1\n",
    "    lb    = 0\n",
    "    thres = 0.5\n",
    "    w     = 0.9    # inertia weight\n",
    "    c1    = 2      # acceleration factor\n",
    "    c2    = 2      # acceleration factor\n",
    "    \n",
    "    N        = opts['N']\n",
    "    max_iter = opts['T']\n",
    "    if 'w' in opts:\n",
    "        w    = opts['w']\n",
    "    if 'c1' in opts:\n",
    "        c1   = opts['c1']\n",
    "    if 'c2' in opts:\n",
    "        c2   = opts['c2'] \n",
    "    \n",
    "    # Dimension\n",
    "    dim = np.size(xtrain, 1)\n",
    "    if np.size(lb) == 1:\n",
    "        ub = ub * np.ones([1, dim], dtype='float')\n",
    "        lb = lb * np.ones([1, dim], dtype='float')\n",
    "        \n",
    "    # Initialize position & velocity\n",
    "    X             = init_position(lb, ub, N, dim)\n",
    "    V, Vmax, Vmin = init_velocity(lb, ub, N, dim) \n",
    "    \n",
    "    # Pre\n",
    "    fit   = np.zeros([N, 1], dtype='float')\n",
    "    Xgb   = np.zeros([1, dim], dtype='float')\n",
    "    fitG  = float('inf')\n",
    "    Xpb   = np.zeros([N, dim], dtype='float')\n",
    "    fitP  = float('inf') * np.ones([N, 1], dtype='float')\n",
    "    curve = np.zeros([1, max_iter], dtype='float') \n",
    "    t     = 0\n",
    "    \n",
    "    while t < max_iter:\n",
    "        # Binary conversion\n",
    "        Xbin = binary_conversion(X, thres, N, dim)\n",
    "        \n",
    "        # Fitness\n",
    "        for i in range(N):\n",
    "            fit[i,0] = Fun(xtrain, ytrain, Xbin[i,:], opts)\n",
    "            if fit[i,0] < fitP[i,0]:\n",
    "                Xpb[i,:]  = X[i,:]\n",
    "                fitP[i,0] = fit[i,0]\n",
    "            if fitP[i,0] < fitG:\n",
    "                Xgb[0,:]  = Xpb[i,:]\n",
    "                fitG      = fitP[i,0]\n",
    "        \n",
    "        # Store result\n",
    "        curve[0,t] = fitG.copy()\n",
    "        print(\"Iteration:\", t + 1)\n",
    "        print(\"Best (PSO):\", curve[0,t])\n",
    "        t += 1\n",
    "        \n",
    "        for i in range(N):\n",
    "            for d in range(dim):\n",
    "                # Update velocity\n",
    "                r1     = random.random()\n",
    "                r2     = random.random()\n",
    "                V[i,d] = w * V[i,d] + c1 * r1 * (Xpb[i,d] - X[i,d]) + c2 * r2 * (Xgb[0,d] - X[i,d]) \n",
    "                # Boundary\n",
    "                V[i,d] = boundary(V[i,d], Vmin[0,d], Vmax[0,d])\n",
    "                # Update position\n",
    "                X[i,d] = X[i,d] + V[i,d]\n",
    "                # Boundary\n",
    "                X[i,d] = boundary(X[i,d], lb[0,d], ub[0,d])\n",
    "    \n",
    "                \n",
    "    # Best feature subset\n",
    "    Gbin       = binary_conversion(Xgb, thres, 1, dim) \n",
    "    Gbin       = Gbin.reshape(dim)\n",
    "    pos        = np.asarray(range(0, dim))    \n",
    "    sel_index  = pos[Gbin == 1]\n",
    "    num_feat   = len(sel_index)\n",
    "    # Create dictionary\n",
    "    pso_data = {'sf': sel_index, 'c': curve, 'nf': num_feat}\n",
    "    \n",
    "    return pso_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fa27eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fmdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75888ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, shuffle=True, random_state = 23)\n",
    "fold = {'xt':xtrain, 'yt':ytrain, 'xv':xtest, 'yv':ytest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3db37060",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1  = 2         # cognitive factor\n",
    "c2  = 2         # social factor \n",
    "w   = 0.9       # inertia weight\n",
    "k     = 5     # k-value in KNN\n",
    "N     = 20    # number of population\n",
    "T     = 100   # maximum number of iterations\n",
    "opts = {'k':k, 'fold':fold, 'N':N, 'T':T, 'w':w, 'c1':c1, 'c2':c2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "982ca217",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Best (PSO): 0.6579612405682007\n",
      "Iteration: 2\n",
      "Best (PSO): 0.5743086558662489\n",
      "Iteration: 3\n",
      "Best (PSO): 0.5743086558662489\n",
      "Iteration: 4\n",
      "Best (PSO): 0.5743086558662489\n",
      "Iteration: 5\n",
      "Best (PSO): 0.5743086558662489\n",
      "Iteration: 6\n",
      "Best (PSO): 0.5450376182204434\n",
      "Iteration: 7\n",
      "Best (PSO): 0.5384636496974945\n",
      "Iteration: 8\n",
      "Best (PSO): 0.5384636496974945\n",
      "Iteration: 9\n",
      "Best (PSO): 0.5384636496974945\n",
      "Iteration: 10\n",
      "Best (PSO): 0.5384636496974945\n",
      "Iteration: 11\n",
      "Best (PSO): 0.5287096625379633\n",
      "Iteration: 12\n",
      "Best (PSO): 0.5287096625379633\n",
      "Iteration: 13\n",
      "Best (PSO): 0.5287096625379633\n",
      "Iteration: 14\n",
      "Best (PSO): 0.5287096625379633\n",
      "Iteration: 15\n",
      "Best (PSO): 0.5287096625379633\n",
      "Iteration: 16\n",
      "Best (PSO): 0.5287096625379633\n",
      "Iteration: 17\n",
      "Best (PSO): 0.5287096625379633\n",
      "Iteration: 18\n",
      "Best (PSO): 0.5287096625379633\n",
      "Iteration: 19\n",
      "Best (PSO): 0.5188576560920218\n",
      "Iteration: 20\n",
      "Best (PSO): 0.5188576560920218\n",
      "Iteration: 21\n",
      "Best (PSO): 0.5188576560920218\n",
      "Iteration: 22\n",
      "Best (PSO): 0.5188576560920218\n",
      "Iteration: 23\n",
      "Best (PSO): 0.5188576560920218\n",
      "Iteration: 24\n",
      "Best (PSO): 0.5188576560920218\n",
      "Iteration: 25\n",
      "Best (PSO): 0.5188576560920218\n",
      "Iteration: 26\n",
      "Best (PSO): 0.5181294705466488\n",
      "Iteration: 27\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 28\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 29\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 30\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 31\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 32\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 33\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 34\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 35\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 36\n",
      "Best (PSO): 0.5176754728498223\n",
      "Iteration: 37\n",
      "Best (PSO): 0.5171550638259458\n",
      "Iteration: 38\n",
      "Best (PSO): 0.5171550638259458\n",
      "Iteration: 39\n",
      "Best (PSO): 0.5171550638259458\n",
      "Iteration: 40\n",
      "Best (PSO): 0.5171550638259458\n",
      "Iteration: 41\n",
      "Best (PSO): 0.512812144844458\n",
      "Iteration: 42\n",
      "Best (PSO): 0.512812144844458\n",
      "Iteration: 43\n",
      "Best (PSO): 0.512812144844458\n",
      "Iteration: 44\n",
      "Best (PSO): 0.512812144844458\n",
      "Iteration: 45\n",
      "Best (PSO): 0.512812144844458\n",
      "Iteration: 46\n",
      "Best (PSO): 0.512812144844458\n",
      "Iteration: 47\n",
      "Best (PSO): 0.512812144844458\n",
      "Iteration: 48\n",
      "Best (PSO): 0.512812144844458\n",
      "Iteration: 49\n",
      "Best (PSO): 0.5113066472575041\n",
      "Iteration: 50\n",
      "Best (PSO): 0.5113066472575041\n",
      "Iteration: 51\n",
      "Best (PSO): 0.5113066472575041\n",
      "Iteration: 52\n",
      "Best (PSO): 0.5113066472575041\n",
      "Iteration: 53\n",
      "Best (PSO): 0.5113066472575041\n",
      "Iteration: 54\n",
      "Best (PSO): 0.5113066472575041\n",
      "Iteration: 55\n",
      "Best (PSO): 0.5113066472575041\n",
      "Iteration: 56\n",
      "Best (PSO): 0.5113066472575041\n",
      "Iteration: 57\n",
      "Best (PSO): 0.5100849975380758\n",
      "Iteration: 58\n",
      "Best (PSO): 0.5078734759334089\n",
      "Iteration: 59\n",
      "Best (PSO): 0.5078734759334089\n",
      "Iteration: 60\n",
      "Best (PSO): 0.5078734759334089\n",
      "Iteration: 61\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 62\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 63\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 64\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 65\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 66\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 67\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 68\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 69\n",
      "Best (PSO): 0.5071578937490121\n",
      "Iteration: 70\n",
      "Best (PSO): 0.5066528265641811\n",
      "Iteration: 71\n",
      "Best (PSO): 0.5066528265641811\n",
      "Iteration: 72\n",
      "Best (PSO): 0.4994279475826195\n",
      "Iteration: 73\n",
      "Best (PSO): 0.4994279475826195\n",
      "Iteration: 74\n",
      "Best (PSO): 0.4994279475826195\n",
      "Iteration: 75\n",
      "Best (PSO): 0.4994279475826195\n",
      "Iteration: 76\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 77\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 78\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 79\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 80\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 81\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 82\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 83\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 84\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 85\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 86\n",
      "Best (PSO): 0.49462259871281755\n",
      "Iteration: 87\n",
      "Best (PSO): 0.494586418563622\n",
      "Iteration: 88\n",
      "Best (PSO): 0.494586418563622\n",
      "Iteration: 89\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 90\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 91\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 92\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 93\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 94\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 95\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 96\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 97\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 98\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 99\n",
      "Best (PSO): 0.49060013543265124\n",
      "Iteration: 100\n",
      "Best (PSO): 0.49060013543265124\n",
      "Run Time --- 46.76497435569763 seconds ---\n",
      "RMSE: 0.5864716912059671\n",
      "Feature Size: 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perform feature selection\n",
    "start_time = time.time()\n",
    "fmdl  = jfs(X_train, y_train, opts)\n",
    "print(\"Run Time --- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "sf    = fmdl['sf']\n",
    "\n",
    "# model with selected features\n",
    "num_train = np.size(xtrain, 0)\n",
    "num_valid = np.size(xtest, 0)\n",
    "x_train   = xtrain[:, sf]\n",
    "y_train   = ytrain.reshape(num_train)  # Solve bug\n",
    "x_valid   = xtest[:, sf]\n",
    "y_valid   = ytest.reshape(num_valid)  # Solve bug\n",
    "\n",
    "mdl       = LogisticRegression()\n",
    "mdl.fit(x_train, y_train)\n",
    "\n",
    "# accuracy\n",
    "y_pred    = mdl.predict(x_valid)\n",
    "RMSE       = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"RMSE:\", RMSE)\n",
    "\n",
    "# number of selected features\n",
    "num_feat = fmdl['nf']\n",
    "print(\"Feature Size:\", num_feat)\n",
    "\n",
    "# plot convergence\n",
    "curve   = fmdl['c']\n",
    "curve   = curve.reshape(np.size(curve,1))\n",
    "x       = np.arange(0, opts['T'], 1.0) + 1.0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, curve, 'o-')\n",
    "ax.set_xlabel('Number of Iterations')\n",
    "ax.set_ylabel('Fitness')\n",
    "ax.set_title('PSO')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c623014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   4,   6,   7,   9,  10,  15,  16,  18,  29,  30,  31,  34,\n",
       "        36,  38,  40,  46,  47,  48,  49,  51,  53,  54,  57,  59,  60,\n",
       "        62,  64,  65,  67,  68,  69,  71,  73,  75,  76,  77,  78,  79,\n",
       "        80,  81,  83,  84,  85,  90,  91,  93,  95,  96,  98, 101, 102,\n",
       "       104, 105, 109, 110, 111, 112, 116, 124, 125, 129, 130, 131, 136,\n",
       "       137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 151, 152, 153,\n",
       "       155, 159, 160, 163, 164, 165, 169, 170, 172, 173, 179, 182, 183,\n",
       "       190, 191, 192, 197, 198, 199, 201, 210, 214, 216, 218, 219, 221,\n",
       "       224, 226, 227, 228, 229, 230, 233, 234, 235, 236, 238, 239, 240,\n",
       "       241, 242, 243, 248, 251, 254, 255, 256, 257, 259, 260, 262, 265,\n",
       "       266, 267, 269, 274, 280, 281, 283, 285, 287, 288, 291, 298, 302,\n",
       "       305, 307, 311, 313, 317, 318, 324, 325, 328, 333, 335, 336, 337,\n",
       "       338, 339, 342, 345, 346, 348, 350, 354, 355, 357, 360, 363, 364,\n",
       "       367, 368, 369, 370, 372, 374, 375, 379, 381, 386, 388, 389, 390,\n",
       "       391, 393, 398, 399, 401, 402, 403, 405, 406, 407, 408, 412, 413,\n",
       "       415, 416, 419, 421, 422, 424, 426, 428, 429, 431, 436, 442, 443,\n",
       "       446, 450, 452, 453, 461, 463, 468, 471, 473, 475, 477, 478, 479,\n",
       "       480, 484, 486, 487, 488, 491, 493, 494, 497, 498, 499, 500, 501,\n",
       "       502, 505, 506, 519, 522, 524, 530, 532, 534, 535, 543, 549, 550,\n",
       "       551, 552, 558, 559, 560, 563, 564, 566, 569, 571, 572, 577, 578,\n",
       "       580, 581, 583, 584])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmdl['sf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "669d1add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature variables\n",
    "X = data.drop(['Time','Pass/Fail'], axis=1)\n",
    "\n",
    "#target variable\n",
    "y = data['Pass/Fail']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feb05cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test.drop(['default.payment.next.month'], axis=1).iloc[:,fmdl['sf']]\n",
    "data = data.drop(['Time'], axis=1)\n",
    "new_data = data.iloc[:,fmdl['sf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44d5214e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>29</th>\n",
       "      <th>...</th>\n",
       "      <th>566</th>\n",
       "      <th>569</th>\n",
       "      <th>571</th>\n",
       "      <th>572</th>\n",
       "      <th>577</th>\n",
       "      <th>578</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>414.8710</td>\n",
       "      <td>10.0433</td>\n",
       "      <td>192.3963</td>\n",
       "      <td>2.0222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.1113</td>\n",
       "      <td>8.95</td>\n",
       "      <td>14.9509</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2230.4222</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>414.7347</td>\n",
       "      <td>9.2599</td>\n",
       "      <td>191.2872</td>\n",
       "      <td>2.2667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.4335</td>\n",
       "      <td>5.92</td>\n",
       "      <td>10.9003</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>416.7075</td>\n",
       "      <td>9.3144</td>\n",
       "      <td>192.7035</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4122</td>\n",
       "      <td>68.8489</td>\n",
       "      <td>2.0293</td>\n",
       "      <td>11.21</td>\n",
       "      <td>9.2721</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2199.0333</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>422.2894</td>\n",
       "      <td>9.6924</td>\n",
       "      <td>192.1557</td>\n",
       "      <td>2.6444</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5611</td>\n",
       "      <td>25.0363</td>\n",
       "      <td>2.0253</td>\n",
       "      <td>9.33</td>\n",
       "      <td>8.5831</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>420.5925</td>\n",
       "      <td>10.3387</td>\n",
       "      <td>191.6037</td>\n",
       "      <td>3.1556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0275</td>\n",
       "      <td>8.83</td>\n",
       "      <td>10.9698</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2179.7333</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>419.3404</td>\n",
       "      <td>10.2397</td>\n",
       "      <td>193.7470</td>\n",
       "      <td>2.2222</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0902</td>\n",
       "      <td>15.4662</td>\n",
       "      <td>2.0153</td>\n",
       "      <td>7.98</td>\n",
       "      <td>11.7256</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2198.5667</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>405.8178</td>\n",
       "      <td>10.2285</td>\n",
       "      <td>193.7889</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7420</td>\n",
       "      <td>20.9118</td>\n",
       "      <td>2.1814</td>\n",
       "      <td>5.48</td>\n",
       "      <td>17.8379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2206.3000</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.2333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4128</td>\n",
       "      <td>29.0954</td>\n",
       "      <td>2.3435</td>\n",
       "      <td>6.49</td>\n",
       "      <td>17.7267</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>401.9153</td>\n",
       "      <td>9.8630</td>\n",
       "      <td>187.3818</td>\n",
       "      <td>2.9667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0902</td>\n",
       "      <td>15.4662</td>\n",
       "      <td>1.9098</td>\n",
       "      <td>9.13</td>\n",
       "      <td>19.2104</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2195.4444</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5889</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0894</td>\n",
       "      <td>21.1128</td>\n",
       "      <td>2.0831</td>\n",
       "      <td>6.81</td>\n",
       "      <td>22.9183</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows Ã— 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              2       4         6       7       9      10        15       16  \\\n",
       "0     2187.7333  1.3602   97.6133  0.1242  0.0162 -0.0034  414.8710  10.0433   \n",
       "1     2230.4222  0.8294  102.3433  0.1247 -0.0005 -0.0148  414.7347   9.2599   \n",
       "2     2186.4111  1.5102   95.4878  0.1241  0.0041  0.0013  416.7075   9.3144   \n",
       "3     2199.0333  1.3204  104.2367  0.1217 -0.0124 -0.0033  422.2894   9.6924   \n",
       "4     2233.3667  1.5334  100.3967  0.1235 -0.0031 -0.0072  420.5925  10.3387   \n",
       "...         ...     ...       ...     ...     ...     ...       ...      ...   \n",
       "1562  2179.7333  1.4843   82.2467  0.1248 -0.0045 -0.0057  419.3404  10.2397   \n",
       "1563  2198.5667  0.8763   98.4689  0.1205 -0.0061 -0.0093  405.8178  10.2285   \n",
       "1564  2206.3000  0.8236   99.4122  0.1208  0.0000  0.0000    0.0000   0.0000   \n",
       "1565  2177.0333  1.5726   98.7978  0.1213 -0.0072  0.0032  401.9153   9.8630   \n",
       "1566  2195.4444  1.5978   85.1011  0.1235  0.0000  0.0000    0.0000   0.0000   \n",
       "\n",
       "            18      29  ...     566      569     571    572      577     578  \\\n",
       "0     192.3963  2.0222  ...  0.0000   0.0000  2.1113   8.95  14.9509  0.0000   \n",
       "1     191.2872  2.2667  ...  0.0000   0.0000  2.4335   5.92  10.9003  0.0096   \n",
       "2     192.7035  2.3333  ...  0.4122  68.8489  2.0293  11.21   9.2721  0.0584   \n",
       "3     192.1557  2.6444  ...  3.5611  25.0363  2.0253   9.33   8.5831  0.0202   \n",
       "4     191.6037  3.1556  ...  0.0000   0.0000  2.0275   8.83  10.9698  0.0000   \n",
       "...        ...     ...  ...     ...      ...     ...    ...      ...     ...   \n",
       "1562  193.7470  2.2222  ...  2.0902  15.4662  2.0153   7.98  11.7256  0.0068   \n",
       "1563  193.7889  2.0000  ...  1.7420  20.9118  2.1814   5.48  17.8379  0.0000   \n",
       "1564    0.0000  2.2333  ...  4.4128  29.0954  2.3435   6.49  17.7267  0.0197   \n",
       "1565  187.3818  2.9667  ...  2.0902  15.4662  1.9098   9.13  19.2104  0.0262   \n",
       "1566    0.0000  2.5889  ...  3.0894  21.1128  2.0831   6.81  22.9183  0.0117   \n",
       "\n",
       "         580       581     583     584  \n",
       "0     0.0000    0.0000  0.0118  0.0035  \n",
       "1     0.0060  208.2045  0.0223  0.0055  \n",
       "2     0.0148   82.8602  0.0157  0.0039  \n",
       "3     0.0044   73.8432  0.0103  0.0025  \n",
       "4     0.0000    0.0000  0.4766  0.1045  \n",
       "...      ...       ...     ...     ...  \n",
       "1562  0.0047  203.1720  0.0143  0.0039  \n",
       "1563  0.0000    0.0000  0.0131  0.0036  \n",
       "1564  0.0025   43.5231  0.0153  0.0041  \n",
       "1565  0.0075   93.4941  0.0178  0.0038  \n",
       "1566  0.0045  137.7844  0.0181  0.0040  \n",
       "\n",
       "[1567 rows x 264 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87833e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1567, 264)\n",
      "Shape of y_train: (1567,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9140127388535032"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature variables\n",
    "X = new_data.values\n",
    "X\n",
    "\n",
    "#target variable\n",
    "y = data['Pass/Fail'].values\n",
    "y\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 23)\n",
    "\n",
    "print(\"Shape of X_train:\", X.shape)\n",
    "print(\"Shape of y_train:\", y.shape)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "LogisticRegression()\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939efa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
