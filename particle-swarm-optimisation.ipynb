{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0717b43",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c3c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86902e",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02ec3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Swarm_Behaviour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bd582e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>xVel1</th>\n",
       "      <th>yVel1</th>\n",
       "      <th>xA1</th>\n",
       "      <th>yA1</th>\n",
       "      <th>xS1</th>\n",
       "      <th>yS1</th>\n",
       "      <th>xC1</th>\n",
       "      <th>yC1</th>\n",
       "      <th>...</th>\n",
       "      <th>yVel200</th>\n",
       "      <th>xA200</th>\n",
       "      <th>yA200</th>\n",
       "      <th>xS200</th>\n",
       "      <th>yS200</th>\n",
       "      <th>xC200</th>\n",
       "      <th>yC200</th>\n",
       "      <th>nAC200</th>\n",
       "      <th>nS200</th>\n",
       "      <th>Swarm_Behaviour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562.05</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-10.70</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175.66</td>\n",
       "      <td>-57.09</td>\n",
       "      <td>2.31</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200.16</td>\n",
       "      <td>-320.07</td>\n",
       "      <td>4.01</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316.99</td>\n",
       "      <td>-906.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>9.17</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.39</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1277.68</td>\n",
       "      <td>908.54</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>8.23</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13.91</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.21</td>\n",
       "      <td>15.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23304</th>\n",
       "      <td>-225.85</td>\n",
       "      <td>128.99</td>\n",
       "      <td>12.19</td>\n",
       "      <td>-7.56</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.06</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23305</th>\n",
       "      <td>-1352.02</td>\n",
       "      <td>-233.03</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-4.37</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.41</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23306</th>\n",
       "      <td>-1360.61</td>\n",
       "      <td>-778.11</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23307</th>\n",
       "      <td>987.11</td>\n",
       "      <td>615.69</td>\n",
       "      <td>-5.61</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.78</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23308</th>\n",
       "      <td>938.12</td>\n",
       "      <td>-924.87</td>\n",
       "      <td>11.18</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23309 rows × 2401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1      y1  xVel1  yVel1   xA1   yA1  xS1  yS1   xC1   yC1  ...  \\\n",
       "0       562.05   -0.62 -10.70  -4.33  0.00  0.00  0.0  0.0  0.00  0.00  ...   \n",
       "1       175.66  -57.09   2.31  -2.67  0.00  0.00  0.0  0.0  0.00  0.00  ...   \n",
       "2       200.16 -320.07   4.01  -6.37  0.00  0.00  0.0  0.0  0.18 -0.26  ...   \n",
       "3       316.99 -906.84   0.85   9.17 -0.17  1.03  0.0  0.0  0.00  0.00  ...   \n",
       "4      1277.68  908.54  -2.02   8.23 -1.00  1.00  0.0  0.0  0.00  0.00  ...   \n",
       "...        ...     ...    ...    ...   ...   ...  ...  ...   ...   ...  ...   \n",
       "23304  -225.85  128.99  12.19  -7.56 -1.00  0.00  0.0  0.0  0.00  0.00  ...   \n",
       "23305 -1352.02 -233.03  -0.86  -4.37 -0.07 -0.55  0.0  0.0  0.28  0.02  ...   \n",
       "23306 -1360.61 -778.11  -2.89  -1.17  0.00  0.00  0.0  0.0  0.00  0.00  ...   \n",
       "23307   987.11  615.69  -5.61  -2.92 -1.00 -1.00  0.0  0.0  0.00  0.00  ...   \n",
       "23308   938.12 -924.87  11.18   2.85  0.10 -0.02  0.0  0.0  0.06  0.31  ...   \n",
       "\n",
       "       yVel200  xA200  yA200  xS200  yS200  xC200  yC200  nAC200  nS200  \\\n",
       "0       -15.15   0.00   0.00   0.00   0.00   0.00   0.00      28      0   \n",
       "1        -3.48   0.00   0.00   0.00   0.00   0.00   0.00       4      0   \n",
       "2        -9.38   0.00   0.00   0.00   0.00  -0.11  -0.30      15      1   \n",
       "3        10.39  -0.26   1.01   0.00   0.00   0.00   0.00      16      0   \n",
       "4        13.91  -1.00   0.00   3.21  15.67   0.00   0.00      12      0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...     ...    ...   \n",
       "23304    -5.06  -1.00  -1.00  -3.99   0.21   0.00   0.00      17      1   \n",
       "23305   -12.41  -0.15  -0.70   0.00   0.00   0.02   0.07      69      1   \n",
       "23306   -14.78   0.00   0.00   0.00   0.00   0.00   0.00      20      1   \n",
       "23307     9.78  -1.00  -1.00   0.00   0.00   0.00   0.00      29      0   \n",
       "23308    -2.90  -0.13  -0.29   1.31   0.38   0.00   0.00       2      1   \n",
       "\n",
       "       Swarm_Behaviour  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "23304              0.0  \n",
       "23305              0.0  \n",
       "23306              0.0  \n",
       "23307              0.0  \n",
       "23308              0.0  \n",
       "\n",
       "[23309 rows x 2401 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623bd25a",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4c932",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901f6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ffd082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>xVel1</th>\n",
       "      <th>yVel1</th>\n",
       "      <th>xA1</th>\n",
       "      <th>yA1</th>\n",
       "      <th>xS1</th>\n",
       "      <th>yS1</th>\n",
       "      <th>xC1</th>\n",
       "      <th>yC1</th>\n",
       "      <th>...</th>\n",
       "      <th>yVel200</th>\n",
       "      <th>xA200</th>\n",
       "      <th>yA200</th>\n",
       "      <th>xS200</th>\n",
       "      <th>yS200</th>\n",
       "      <th>xC200</th>\n",
       "      <th>yC200</th>\n",
       "      <th>nAC200</th>\n",
       "      <th>nS200</th>\n",
       "      <th>Swarm_Behaviour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10795</td>\n",
       "      <td>9519</td>\n",
       "      <td>240</td>\n",
       "      <td>735</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>356</td>\n",
       "      <td>332</td>\n",
       "      <td>212</td>\n",
       "      <td>226</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8651</td>\n",
       "      <td>9096</td>\n",
       "      <td>1432</td>\n",
       "      <td>899</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>855</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>356</td>\n",
       "      <td>332</td>\n",
       "      <td>212</td>\n",
       "      <td>226</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8774</td>\n",
       "      <td>6531</td>\n",
       "      <td>1596</td>\n",
       "      <td>558</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>271</td>\n",
       "      <td>219</td>\n",
       "      <td>...</td>\n",
       "      <td>346</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>356</td>\n",
       "      <td>332</td>\n",
       "      <td>201</td>\n",
       "      <td>196</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9514</td>\n",
       "      <td>698</td>\n",
       "      <td>1286</td>\n",
       "      <td>2016</td>\n",
       "      <td>83</td>\n",
       "      <td>196</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>2108</td>\n",
       "      <td>74</td>\n",
       "      <td>194</td>\n",
       "      <td>356</td>\n",
       "      <td>332</td>\n",
       "      <td>212</td>\n",
       "      <td>226</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15926</td>\n",
       "      <td>16031</td>\n",
       "      <td>1000</td>\n",
       "      <td>1922</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>2286</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>588</td>\n",
       "      <td>648</td>\n",
       "      <td>212</td>\n",
       "      <td>226</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1     y1  xVel1  yVel1  xA1  yA1  xS1  yS1  xC1  yC1  ...  yVel200  \\\n",
       "0  10795   9519    240    735  100   98  372  351  253  245  ...       83   \n",
       "1   8651   9096   1432    899  100   98  372  351  253  245  ...      855   \n",
       "2   8774   6531   1596    558  100   98  372  351  271  219  ...      346   \n",
       "3   9514    698   1286   2016   83  196  372  351  253  245  ...     2108   \n",
       "4  15926  16031   1000   1922    0  193  372  351  253  245  ...     2286   \n",
       "\n",
       "   xA200  yA200  xS200  yS200  xC200  yC200  nAC200  nS200  Swarm_Behaviour  \n",
       "0    100    100    356    332    212    226      28      0                0  \n",
       "1    100    100    356    332    212    226       4      0                0  \n",
       "2    100    100    356    332    201    196      15      1                0  \n",
       "3     74    194    356    332    212    226      16      0                0  \n",
       "4      1    100    588    648    212    226      12      0                0  \n",
       "\n",
       "[5 rows x 2401 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2684ec0",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d255f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = data.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_scaled = min_max_scaler.fit_transform(X)\n",
    "df = pd.DataFrame(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d31084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1251a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>xVel1</th>\n",
       "      <th>yVel1</th>\n",
       "      <th>xA1</th>\n",
       "      <th>yA1</th>\n",
       "      <th>xS1</th>\n",
       "      <th>yS1</th>\n",
       "      <th>xC1</th>\n",
       "      <th>yC1</th>\n",
       "      <th>...</th>\n",
       "      <th>yVel200</th>\n",
       "      <th>xA200</th>\n",
       "      <th>yA200</th>\n",
       "      <th>xS200</th>\n",
       "      <th>yS200</th>\n",
       "      <th>xC200</th>\n",
       "      <th>yC200</th>\n",
       "      <th>nAC200</th>\n",
       "      <th>nS200</th>\n",
       "      <th>Swarm_Behaviour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.634664</td>\n",
       "      <td>0.567249</td>\n",
       "      <td>0.105125</td>\n",
       "      <td>0.299389</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.500713</td>\n",
       "      <td>0.513185</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034411</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.507614</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.467991</td>\n",
       "      <td>0.475789</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.508613</td>\n",
       "      <td>0.542042</td>\n",
       "      <td>0.627245</td>\n",
       "      <td>0.366191</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.500713</td>\n",
       "      <td>0.513185</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354478</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.507614</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.467991</td>\n",
       "      <td>0.475789</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.515845</td>\n",
       "      <td>0.389190</td>\n",
       "      <td>0.699080</td>\n",
       "      <td>0.227291</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.500713</td>\n",
       "      <td>0.549696</td>\n",
       "      <td>0.442424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143449</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.507614</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.443709</td>\n",
       "      <td>0.412632</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.559351</td>\n",
       "      <td>0.041595</td>\n",
       "      <td>0.563294</td>\n",
       "      <td>0.821181</td>\n",
       "      <td>0.453552</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.500713</td>\n",
       "      <td>0.513185</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873964</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.984772</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.467991</td>\n",
       "      <td>0.475789</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.936328</td>\n",
       "      <td>0.955307</td>\n",
       "      <td>0.438020</td>\n",
       "      <td>0.782892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979695</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.500713</td>\n",
       "      <td>0.513185</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947761</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.507614</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.467991</td>\n",
       "      <td>0.475789</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        y1     xVel1     yVel1       xA1       yA1       xS1  \\\n",
       "0  0.634664  0.567249  0.105125  0.299389  0.546448  0.497462  0.529915   \n",
       "1  0.508613  0.542042  0.627245  0.366191  0.546448  0.497462  0.529915   \n",
       "2  0.515845  0.389190  0.699080  0.227291  0.546448  0.497462  0.529915   \n",
       "3  0.559351  0.041595  0.563294  0.821181  0.453552  0.994924  0.529915   \n",
       "4  0.936328  0.955307  0.438020  0.782892  0.000000  0.979695  0.529915   \n",
       "\n",
       "        yS1       xC1       yC1  ...   yVel200     xA200     yA200     xS200  \\\n",
       "0  0.500713  0.513185  0.494949  ...  0.034411  0.515464  0.507614  0.509299   \n",
       "1  0.500713  0.513185  0.494949  ...  0.354478  0.515464  0.507614  0.509299   \n",
       "2  0.500713  0.549696  0.442424  ...  0.143449  0.515464  0.507614  0.509299   \n",
       "3  0.500713  0.513185  0.494949  ...  0.873964  0.381443  0.984772  0.509299   \n",
       "4  0.500713  0.513185  0.494949  ...  0.947761  0.005155  0.507614  0.841202   \n",
       "\n",
       "      yS200     xC200     yC200    nAC200     nS200  Swarm_Behaviour  \n",
       "0  0.501511  0.467991  0.475789  0.205882  0.000000              0.0  \n",
       "1  0.501511  0.467991  0.475789  0.029412  0.000000              0.0  \n",
       "2  0.501511  0.443709  0.412632  0.110294  0.015625              0.0  \n",
       "3  0.501511  0.467991  0.475789  0.117647  0.000000              0.0  \n",
       "4  0.978852  0.467991  0.475789  0.088235  0.000000              0.0  \n",
       "\n",
       "[5 rows x 2401 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb4274",
   "metadata": {},
   "source": [
    "#### Define Target and Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd5305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature variables\n",
    "X = df.drop(['Swarm_Behaviour'], axis=1).values\n",
    "\n",
    "#target variable\n",
    "y = df['Swarm_Behaviour'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f30976",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd131fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce8e15d",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f09cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23309, 2401)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c04058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23309 entries, 0 to 23308\n",
      "Columns: 2401 entries, x1 to Swarm_Behaviour\n",
      "dtypes: float64(2401)\n",
      "memory usage: 427.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65436357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    15355\n",
       "1.0     7954\n",
       "Name: Swarm_Behaviour, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Swarm_Behaviour\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1a3ea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedi\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Swarm_Behaviour', ylabel='count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['Swarm_Behaviour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa50451",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae446c",
   "metadata": {},
   "source": [
    "### In this work, at first classification models has been applied without optimization\n",
    "#### Classifier Used-\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Decision Tree\n",
    "- Random Forrest\n",
    "- Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea212de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression(solver='lbfgs', max_iter=2000)\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC\n",
    "models['Support Vector Machines'] = SVC(kernel='linear')\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()\n",
    "\n",
    "# Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "models['Neural Networks'] = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cc8d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy = {}\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    # Fit the classifier\n",
    "    models[key].fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = models[key].predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy[key] = accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "834db49d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.880023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.877020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.872015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.870013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.888460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.894323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy\n",
       "Logistic Regression      0.880023\n",
       "Support Vector Machines  0.877020\n",
       "Decision Trees           0.872015\n",
       "Random Forest            0.870013\n",
       "K-Nearest Neighbor       0.888460\n",
       "Neural Networks          0.894323"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1b7b6",
   "metadata": {},
   "source": [
    "## Particle Swarm Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "561da2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error rate\n",
    "def error_rate(xtrain, ytrain, x, opts):\n",
    "    # parameters\n",
    "    fold = opts['fold']\n",
    "    xt = fold['xt']\n",
    "    yt = fold['yt']\n",
    "    xv = fold['xv']\n",
    "    yv = fold['yv']\n",
    "    # number of instances\n",
    "    num_train = np.size(xt, 0)\n",
    "    num_valid = np.size(xv, 0)\n",
    "    # Define selected features\n",
    "    xtrain = xt[:, x == 1]\n",
    "    ytrain = yt.reshape(num_train)\n",
    "    xvalid = xv[:, x == 1]\n",
    "    yvalid = yv.reshape(num_valid)\n",
    "    # Training\n",
    "    mdl     = LinearRegression()\n",
    "    mdl.fit(xtrain, ytrain)\n",
    "    # Prediction\n",
    "    ypred   = mdl.predict(xvalid)\n",
    "    error   = mean_squared_error(yvalid, ypred, squared=False)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79b1f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rate & Feature size\n",
    "def Fun(xtrain, ytrain, x, opts):\n",
    "    # parameters\n",
    "    alpha = 0.99\n",
    "    beta = 1 - alpha\n",
    "    # original feature size\n",
    "    max_feat = len(x)\n",
    "    # Number of selected features\n",
    "    num_feat = np.sum(x == 1)\n",
    "    # Solve if no feature selected\n",
    "    if num_feat == 0:\n",
    "        cost = 1\n",
    "    else:\n",
    "        # Get error rate\n",
    "        error = error_rate(xtrain, ytrain, x, opts)\n",
    "        # Objective function\n",
    "        cost = alpha * error + beta * (num_feat / max_feat)\n",
    "        \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e53a625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_position(lb, ub, N, dim):\n",
    "    X = np.zeros([N, dim], dtype='float')\n",
    "    for i in range(N):\n",
    "        for d in range(dim):\n",
    "            X[i,d] = lb[0,d] + (ub[0,d] - lb[0,d]) * random.random()        \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8af805b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_velocity(lb, ub, N, dim):\n",
    "    V    = np.zeros([N, dim], dtype='float')\n",
    "    Vmax = np.zeros([1, dim], dtype='float')\n",
    "    Vmin = np.zeros([1, dim], dtype='float')\n",
    "    # Maximum & minimum velocity\n",
    "    for d in range(dim):\n",
    "        Vmax[0,d] = (ub[0,d] - lb[0,d]) / 2\n",
    "        Vmin[0,d] = -Vmax[0,d]\n",
    "        \n",
    "    for i in range(N):\n",
    "        for d in range(dim):\n",
    "            V[i,d] = Vmin[0,d] + (Vmax[0,d] - Vmin[0,d]) * random.random()\n",
    "        \n",
    "    return V, Vmax, Vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd99975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_conversion(X, thres, N, dim):\n",
    "    Xbin = np.zeros([N, dim], dtype='int')\n",
    "    for i in range(N):\n",
    "        for d in range(dim):\n",
    "            if X[i,d] > thres:\n",
    "                Xbin[i,d] = 1\n",
    "            else:\n",
    "                Xbin[i,d] = 0\n",
    "    \n",
    "    return Xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a5c6851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary(x, lb, ub):\n",
    "    if x < lb:\n",
    "        x = lb\n",
    "    if x > ub:\n",
    "        x = ub\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d32d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jfs(xtrain, ytrain, opts):\n",
    "    # Parameters\n",
    "    ub    = 1\n",
    "    lb    = 0\n",
    "    thres = 0.5\n",
    "    w     = 0.9    # inertia weight\n",
    "    c1    = 2      # acceleration factor\n",
    "    c2    = 2      # acceleration factor\n",
    "    \n",
    "    N        = opts['N']\n",
    "    max_iter = opts['T']\n",
    "    if 'w' in opts:\n",
    "        w    = opts['w']\n",
    "    if 'c1' in opts:\n",
    "        c1   = opts['c1']\n",
    "    if 'c2' in opts:\n",
    "        c2   = opts['c2'] \n",
    "    \n",
    "    # Dimension\n",
    "    dim = np.size(xtrain, 1)\n",
    "    if np.size(lb) == 1:\n",
    "        ub = ub * np.ones([1, dim], dtype='float')\n",
    "        lb = lb * np.ones([1, dim], dtype='float')\n",
    "        \n",
    "    # Initialize position & velocity\n",
    "    X             = init_position(lb, ub, N, dim)\n",
    "    V, Vmax, Vmin = init_velocity(lb, ub, N, dim) \n",
    "    \n",
    "    # Pre\n",
    "    fit   = np.zeros([N, 1], dtype='float')\n",
    "    Xgb   = np.zeros([1, dim], dtype='float')\n",
    "    fitG  = float('inf')\n",
    "    Xpb   = np.zeros([N, dim], dtype='float')\n",
    "    fitP  = float('inf') * np.ones([N, 1], dtype='float')\n",
    "    curve = np.zeros([1, max_iter], dtype='float') \n",
    "    t     = 0\n",
    "    \n",
    "    while t < max_iter:\n",
    "        # Binary conversion\n",
    "        Xbin = binary_conversion(X, thres, N, dim)\n",
    "        \n",
    "        # Fitness\n",
    "        for i in range(N):\n",
    "            fit[i,0] = Fun(xtrain, ytrain, Xbin[i,:], opts)\n",
    "            if fit[i,0] < fitP[i,0]:\n",
    "                Xpb[i,:]  = X[i,:]\n",
    "                fitP[i,0] = fit[i,0]\n",
    "            if fitP[i,0] < fitG:\n",
    "                Xgb[0,:]  = Xpb[i,:]\n",
    "                fitG      = fitP[i,0]\n",
    "        \n",
    "        # Store result\n",
    "        curve[0,t] = fitG.copy()\n",
    "        print(\"Iteration:\", t + 1)\n",
    "        print(\"Best (PSO):\", curve[0,t])\n",
    "        t += 1\n",
    "        \n",
    "        for i in range(N):\n",
    "            for d in range(dim):\n",
    "                # Update velocity\n",
    "                r1     = random.random()\n",
    "                r2     = random.random()\n",
    "                V[i,d] = w * V[i,d] + c1 * r1 * (Xpb[i,d] - X[i,d]) + c2 * r2 * (Xgb[0,d] - X[i,d]) \n",
    "                # Boundary\n",
    "                V[i,d] = boundary(V[i,d], Vmin[0,d], Vmax[0,d])\n",
    "                # Update position\n",
    "                X[i,d] = X[i,d] + V[i,d]\n",
    "                # Boundary\n",
    "                X[i,d] = boundary(X[i,d], lb[0,d], ub[0,d])\n",
    "    \n",
    "                \n",
    "    # Best feature subset\n",
    "    Gbin       = binary_conversion(Xgb, thres, 1, dim) \n",
    "    Gbin       = Gbin.reshape(dim)\n",
    "    pos        = np.asarray(range(0, dim))    \n",
    "    sel_index  = pos[Gbin == 1]\n",
    "    num_feat   = len(sel_index)\n",
    "    # Create dictionary\n",
    "    pso_data = {'sf': sel_index, 'c': curve, 'nf': num_feat}\n",
    "    \n",
    "    return pso_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "577cbfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, shuffle=True, random_state = 23)\n",
    "fold = {'xt':xtrain, 'yt':ytrain, 'xv':xtest, 'yv':ytest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0db467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1  = 2         # cognitive factor\n",
    "c2  = 2         # social factor \n",
    "w   = 0.9       # inertia weight\n",
    "k     = 5     # k-value in KNN\n",
    "N     = 20    # number of population\n",
    "T     = 100   # maximum number of iterations\n",
    "opts = {'k':k, 'fold':fold, 'N':N, 'T':T, 'w':w, 'c1':c1, 'c2':c2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3965dea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Best (PSO): 0.24306961391265905\n",
      "Iteration: 2\n",
      "Best (PSO): 0.24306961391265905\n",
      "Iteration: 3\n",
      "Best (PSO): 0.24079219948223302\n",
      "Iteration: 4\n",
      "Best (PSO): 0.24079219948223302\n",
      "Iteration: 5\n",
      "Best (PSO): 0.24079219948223302\n",
      "Iteration: 6\n",
      "Best (PSO): 0.24079219948223302\n",
      "Iteration: 7\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 8\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 9\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 10\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 11\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 12\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 13\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 14\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 15\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 16\n",
      "Best (PSO): 0.24069079443801605\n",
      "Iteration: 17\n",
      "Best (PSO): 0.2399800594805869\n",
      "Iteration: 18\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 19\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 20\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 21\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 22\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 23\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 24\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 25\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 26\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 27\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 28\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 29\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 30\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 31\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 32\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 33\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 34\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 35\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 36\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 37\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 38\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 39\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 40\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 41\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 42\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 43\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 44\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 45\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 46\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 47\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 48\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 49\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 50\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 51\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 52\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 53\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 54\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 55\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 56\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 57\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 58\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 59\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 60\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 61\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 62\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 63\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 64\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 65\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 66\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 67\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 68\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 69\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 70\n",
      "Best (PSO): 0.23959625014395627\n",
      "Iteration: 71\n",
      "Best (PSO): 0.23957784608133892\n",
      "Iteration: 72\n",
      "Best (PSO): 0.23957784608133892\n",
      "Iteration: 73\n",
      "Best (PSO): 0.23957784608133892\n",
      "Iteration: 74\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 75\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 76\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 77\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 78\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 79\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 80\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 81\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 82\n",
      "Best (PSO): 0.23911819087529687\n",
      "Iteration: 83\n",
      "Best (PSO): 0.23898730859397777\n",
      "Iteration: 84\n",
      "Best (PSO): 0.23898730859397777\n",
      "Iteration: 85\n",
      "Best (PSO): 0.23898730859397777\n",
      "Iteration: 86\n",
      "Best (PSO): 0.23898730859397777\n",
      "Iteration: 87\n",
      "Best (PSO): 0.23898730859397777\n",
      "Iteration: 88\n",
      "Best (PSO): 0.23898730859397777\n",
      "Iteration: 89\n",
      "Best (PSO): 0.23898730859397777\n",
      "Iteration: 90\n",
      "Best (PSO): 0.23898730859397777\n",
      "Iteration: 91\n",
      "Best (PSO): 0.23881871443377375\n",
      "Iteration: 92\n",
      "Best (PSO): 0.23845847923673652\n",
      "Iteration: 93\n",
      "Best (PSO): 0.23841116131318382\n",
      "Iteration: 94\n",
      "Best (PSO): 0.2378805983461631\n",
      "Iteration: 95\n",
      "Best (PSO): 0.2378805983461631\n",
      "Iteration: 96\n",
      "Best (PSO): 0.23746725175173403\n",
      "Iteration: 97\n",
      "Best (PSO): 0.23745858213410626\n",
      "Iteration: 98\n",
      "Best (PSO): 0.23745858213410626\n",
      "Iteration: 99\n",
      "Best (PSO): 0.23745858213410626\n",
      "Iteration: 100\n",
      "Best (PSO): 0.23745858213410626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.33107342027050374\n",
      "Feature Size: 1170\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmH0lEQVR4nO3dfZxV1X3v8c+XYXCOIAyiUhlAiCEYojxEakz0VSFJgyZepaY2etWmjV6vbWwebkMqbeOtsY0mNL1Jc7XW2pg0pjEmIjFGg0adpCklPqEgEZSrRhmMj4yIDDADv/vH3kOOxxnmHDh7zpmzv+/Xa17svfba+6zfAPObvdbeaykiMDMzK9ewWjfAzMyGFicOMzOriBOHmZlVxInDzMwq4sRhZmYVceIwM7OKOHGYmVlFnDjMqkzS05K6JG2V9Lyk6yWNkvQOSXdK2iypU9KDkj5YdF6rpH+S9GtJ2yStkfTHtYzFrC9OHGbZ+G8RMQp4J/DbwF8DPwTuAsYDhwGfALYASBoB/AQ4Ang3MAZYBFwp6X8NeuvN9mJ4rRtg1sgiokPSHcDRwFTgXyJiZ3r4P4uqngdMBk6KiNfTsh9L+gTwr5Kui4gtg9Zws73wHYdZhiRNAj4IrAI2ADdIWihpfEnV3wXuKEoavW4GWkjuQszqghOHWTaWSeoEfg78FPgCMB94Gvgy8Jykn0maltY/BHiu9CIR0QO8lB43qwtOHGbZWBgRrRFxRET8aUR0RcTGiLg4Io4kGct4Hfi3tP5LwOGlF5E0nCRpvDRoLTcbgBOHWQ1ExLPAVSRjH5AMjJ8iaWRJ1Q8DO4CVg9g8s71y4jAbBJLGSrpM0lslDZN0CPAxfpMQvgVsBL4naYqkZkkLgH8E/iYiXq1R083exInDbHDsBKaQ3FlsAR4luZP4I4CI2AG8H3gW+EVa5x+Av4qIJYPfXLP+yQs5mZlZJXzHYWZmFXHiMDOzijhxmJlZRZw4zMysIrmYq+qQQw6JKVOmlF3/9ddfZ+TI0sfpG18e485jzJDPuPMYM+xf3A8++OBLEXFoaXkuEseUKVN44IEHyq7f3t7OvHnzsmtQncpj3HmMGfIZdx5jhv2LW9Kv+ip3V5WZmVXEicPMzCrixGFmZhVx4jAzs4o4cZiZWUVy8VTVvli2qoMly9ezqbOLMYVmJOjc1s2E1gKLFkxn4Zy2WjfRzKwmnDj6sGJTN9+6ew1d3bsA6Ozq3nOso7OLxUvXADh5mFkuuauqDzc/3r0nafSlq3sXS5avH8QWmZnVj0wTh6STJa2XtEHSJX0cP0fS6vRrhaRZJcebJK2SdFtR2eVp/Ycl3SlpQrXb/fL2gaea39TZVe2PNTMbEjJLHJKaSJbGPAWYAZwtaUZJtaeAkyJiJnA5cG3J8U8Cj5WULYmImRExG7gNuLTabR/XogHrTGgtVPtjzcyGhCzvOI4DNkTEkxGxE7gROL24QkSsiIjN6e5KYGLvMUkTgQ8B15Wcs6VodyRQ9ZWoPvy2ZgrNTf0eLzQ3sWjB9Gp/rJnZkJDl4HgbyTKYvTYC79pL/fOBO4r2vwJ8FjiotKKkvwP+EHgVmN/XxSRdCFwIMH78eNrb28tu+MzROzjv7Qdw8+O7eXl7MHI49ATs2AVjDxBnTm+i9dUnaG9/ouxrDgVbt26t6PvUCPIYM+Qz7jzGDBnFHRGZfAFnAtcV7Z8HfK2fuvNJuqTGpfunAlen2/OA2/o5bzFw2UBtOfbYY6MS995775vKlq3aGEf8xW3xxPOvVXStoaSvuBtdHmOOyGfceYw5Yv/iBh6IPn6mZtlVtRGYVLQ/EdhUWknSTJLuqNMj4uW0+ATgNElPk3RxvVfSDX18xr8DH65mo/vT23W1fS9PW5mZ5UGWieN+YJqkqZJGAGcBtxZXkDQZWAqcFxGP95ZHxOKImBgRU9Lz7omIc9NzphVd4jRgXYYx7NHixGFmBmQ4xhERPZIuBpYDTcDXI2KtpIvS49eQPBE1DrhaEkBPRMwd4NJXSpoO7AZ+BVyUVQzFCiOSxLG39zvMzPIg0zfHI+J24PaSsmuKti8ALhjgGu1Ae9H+oHRNlertqura6cRhZvnmN8fL1NtV5TsOM8s7J44y9XZV7ejeXeOWmJnVlhNHmVqGJ98q33GYWd45cZTJg+NmZgknjjK1DPfguJkZOHGUbdgwccDwYX6Pw8xyz4mjAoURTe6qMrPcc+KoQKG5yXccZpZ7ThwVaGluosuP45pZzjlxVKClucmD42aWe04cFSg0e3DczMyJowIeHDczc+KoiAfHzcycOCpyQLPvOMzMnDgqUGhuYrsHx80s55w4KlDwHYeZmRNHJTw4bmbmxFGRluYmtnfvJiJq3RQzs5px4qhAS3Py7drR47fHzSy/nDgq4HXHzcycOCpS8LrjZmZOHJXwKoBmZk4cFWlJ7zj89riZ5ZkTRwWcOMzMnDgq8pvBcT9VZWb55cRRAQ+Om5llnDgknSxpvaQNki7p4/g5klanXyskzSo53iRplaTbisqWSFqXnnOLpNYsYyhWGJF8u5w4zCzPMksckpqAq4BTgBnA2ZJmlFR7CjgpImYClwPXlhz/JPBYSdldwNHpOY8Di6vd9v7sGePwexxmlmNZ3nEcB2yIiCcjYidwI3B6cYWIWBERm9PdlcDE3mOSJgIfAq4rOefOiOjp65ys9XZVbe9x4jCz/Bqe4bXbgGeL9jcC79pL/fOBO4r2vwJ8FjhoL+d8DPhuXwckXQhcCDB+/Hja29sHbHCvrVu39ll/e08yR9Wj6x6nfcfTZV9vqOgv7kaWx5ghn3HnMWbIJu4sE4f6KOtzdkBJ80kSx4np/qnACxHxoKR5/ZzzV0AP8O2+jkfEtaRdX3Pnzo158/q8TJ/a29vpq/6u3QE/uZ0Jk6Ywb97byr7eUNFf3I0sjzFDPuPOY8yQTdxZJo6NwKSi/YnAptJKkmaSdEedEhEvp8UnAKdJ+iDQAoyWdENEnJue81HgVOB9MYhT1TYNEyOGD/PguJnlWpZjHPcD0yRNlTQCOAu4tbiCpMnAUuC8iHi8tzwiFkfExIiYkp53T1HSOBn4C+C0iNiWYfv75FUAzSzvMrvjiIgeSRcDy4Em4OsRsVbSRenxa4BLgXHA1ZIAeiJi7gCX/r/AAcBd6TkrI+KijMJ4k0K6JoeZWV5l2VVFRNwO3F5Sdk3R9gXABQNcox1oL9p/a1UbWaGWZndVmVm++c3xCrV43XEzyzknjgoVRjR5kkMzyzUnjgoVmpu8AqCZ5ZoTR4UKzU1+c9zMcs2Jo0ItvuMws5xz4qhQix/HNbOcc+KoUGGEH8c1s3xz4qiQB8fNLO+cOCpUSN/jGMQpsszM6ooTR4VaRiRrcuzo8TiHmeWTE0eFWoanizl5nMPMcsqJo0KF9I7DA+RmlldOHBXqXT7WA+RmlldOHBVqafYdh5nlmxNHhXq7qvwSoJnllRNHhVqGJ98yD46bWV45cVRoz+C4xzjMLKecOCpU8BiHmeWcE0eFPDhuZnnnxFGh3q6qHU4cZpZTThwV8h2HmeWdE0eFep+q6trpx3HNLJ+cOCo0vGkYI5q8JoeZ5ZcTxz5oaR7m9zjMLLecOPZBYUSTE4eZ5ZYTxz5oSRdzMjPLo0wTh6STJa2XtEHSJX0cP0fS6vRrhaRZJcebJK2SdFtR2ZmS1kraLWlulu3vj5ePNbM8yyxxSGoCrgJOAWYAZ0uaUVLtKeCkiJgJXA5cW3L8k8BjJWWPAmcAP6t6o8vkOw4zy7Ms7ziOAzZExJMRsRO4ETi9uEJErIiIzenuSmBi7zFJE4EPAdeVnPNYRKzPsN0DKjR7jMPM8mt4htduA54t2t8IvGsv9c8H7ija/wrwWeCgfflwSRcCFwKMHz+e9vb2ss/dunXrXutve207nTuiomsOBQPF3YjyGDPkM+48xgzZxJ1l4lAfZdFnRWk+SeI4Md0/FXghIh6UNG9fPjwiriXt+po7d27Mm1f+Zdrb29lb/e91PMTrz7/GvHkn7UvT6tZAcTeiPMYM+Yw7jzFDNnFnmTg2ApOK9icCm0orSZpJ0h11SkS8nBafAJwm6YNACzBa0g0RcW6G7S3bAc3DPDhuZrmV5RjH/cA0SVMljQDOAm4triBpMrAUOC8iHu8tj4jFETExIqak591TL0kDPMZhZvmW2R1HRPRIuhhYDjQBX4+ItZIuSo9fA1wKjAOulgTQExF7fcRW0u8BXwMOBX4k6eGIWJBVHKWWrergBw93sHXHLmZfdicSdG7rZkyhec/2hNYC8486lHvXvcimzi4mtBZYtGA6C+e0DVYzzcwyk2VXFRFxO3B7Sdk1RdsXABcMcI12oL1o/xbglmq2s1zLVnWweOmaPY/idnZ17zlWvN3R2cUNK595w/7ipWsAnDzMbMjzm+MVWLJ8/T6/v9HVvYsly2v6FLGZWVU4cVRgU2dXTc83M6sHmXZVNZoJrQU69uOHf0C/4yJZbHtsxcyy4MRRgUULpr9hjGNf9DcuksW2x1bMLAvuqqrAwjltXHHGMbS1FhDQWmhm7IHNb9puay1w7vGTaWst1LjFHlsxs+qr+I5D0lhgUkSszqA9dW/hnLaKfnufesmP+n5dfhB5bMXMqqmsOw5J7ZJGSzoYeAS4XtI/ZNu0xjChDu466qENZtY4yu2qGhMRW0imM78+Io4F3p9dsxrHogXTKTQ31ezzC81NLFowvWafb2aNp9zEMVzS4cAfALcNVNl+o9xxkWputxaaARjdMpwrzjjGA+NmVlXljnF8nmTqkJ9HxP2S3gI8kV2zGkul4yLVMPvzd3LqzMOdNMys6spKHBHxPeB7RftPAh/OqlG2/9paC3Rs9qC4mVVfuYPjX0oHx5sl3S3pJUl1M1utvVnbfr6saGbWn3LHOD6QDo6fSrLOxtuARZm1yvbbxLEHsnFzFxG1fhjYzBpNuYmjOf3zg8B3IuKVjNpjVdI2tsC2nbvo3NY9cGUzswqUmzh+KGkdMBe4W9KhwPbsmmX7a+LY5N2NjR7nMLMqKytxRMQlwLuBuRHRDWwDTs+yYbZ/eqc76ejcVuOWmFmjKXdw/EDg48A/pUUTSO4+rE75jsPMslJuV9X1wE7gPen+RuBvM2mRVcWYQjOjDhjuxGFmVVdu4jgyIr4EdANERBegzFpl+00Sba0FJw4zq7pyE8dOSQWStYiQdCSwI7NWWVVMHOt3Ocys+spNHP8b+DEwSdK3gbuBz2bWKquKtrEFOjZ7cNzMqqvcKUfukvQQcDxJF9UnI+KlTFtm+23i2AJbtvewZXs3o1uaBz7BzKwMlawA2AJsBrYAMyT9TjZNsmppaz0QwHNWmVlVlXXHIemLwEeAtcDutDiAn2XULquCtqJHct9++Ogat8bMGkW506ovBKZHhAfEh5Dedzk8zmFm1VRuV9WT/Ga+Khsixo0cQUvzMD+Sa2ZVVW7i2AY8LOmfJf1j79dAJ0k6WdJ6SRskXdLH8XMkrU6/VkiaVXK8SdIqSbcVlR0s6S5JT6R/ji0zhtzpfZfDj+SaWTWVmzhuBS4HVgAPpl8P7O0ESU3AVcApwAzgbEkzSqo9BZwUETPT619bcvyTwGMlZZcAd0fENJLHgt+UkCyxbFUHGzd3ccejv+aEK+9h2aqOWjfJzBpAuYmjNSK+WfwFDPSb/nHAhoh4MiJ2AjdSMjFiRKyIiM3p7kpgYu8xSROBDwHXlVz3dOCb6fY3ScZfrMSyVR0sXrqGHT3JswwdnV0sXrrGycPM9pvKWehH0kMR8c6SslURMWcv5/w+cHJEXJDunwe8KyIu7qf+Z4Cjiup/H7gCOAj4TEScmpZ3RkRr0XmbI+JNSUzShcCFAOPHjz/2xhtvHDDOXlu3bmXUqFFl169Hf96+jZe3v/nvdlyL+PK8A/s8pxHirlQeY4Z8xp3HmGH/4p4/f/6DEfGmCW33+lSVpLOB/w5MlXRr0aGDgJcH+My+5rLqM0tJmg+cD5yY7p8KvBARD0qaN8Dn9CkiriXt+po7d27Mm1f+Zdrb26mkfj165cc/6rt8e/QbWyPEXak8xgz5jDuPMUM2cQ/0OO4K4DngEODLReWvAasHOHcjMKlofyKwqbSSpJkk3VGnRERvMjoBOE3SB0lePBwt6YaIOBd4XtLhEfGcpMOBFwZoRy5N6GdQfEK6ToeZ2b7a6xhHRPwqItoj4t0R8dOir4ciomeAa98PTJM0VdII4CySQfY9JE0GlgLnRcTjRZ+7OCImRsSU9Lx70qRBeo2PptsfBX5QZqy5smjBdArNTW8oKzQ3sWjB9Bq1yMwaxUBdVT+PiBMlvcYbu5kERET0+zpyRPRIuhhYDjQBX4+ItZIuSo9fA1wKjAOulgTQ01d/WokrgZsknQ88A5w5QP1cWjinDYAly9fT0dnFMMEXfu/oPeVmZvtqoK6qcwAi4qB9uXhE3A7cXlJ2TdH2BcAFA1yjHWgv2n8ZeN++tCdvFs5pY+GcNr618ld8btmjzJ1ycK2bZGYNYKDHcW/p3ZB0c8ZtsYwcOzl56OzBX20eoKaZ2cAGShzFT0a9JcuGWHam/9ZBjDpguBOHmVXFQIkj+tm2IaRpmJgzuZUHnDjMrAoGShyzJG1JB8dnpttbJL0mactgNNCq452Tx7L+11t4bXt3rZtiZkPcQI/jNkXE6Ig4KCKGp9u9+17gYQg59oix7A545NlXa90UMxviKlkB0IawOZNbkTxAbmb7r9yFnGyIu/uxF2iS+D8/eZybHniW+Ucdyr3rXmRTZxdjCs1IsHlbN60/vRMJOrd17ymv5faE1kKfba3WZ+xvzFm3L6vvZUdnV93/XU9oLbBowXS/e1SHyprkcKibO3duPPDAXmeBf4NGm9Omd6bcru5dtW6KWUUKzU1cccYxVUkejfb/ulz7E7ekPic5dFdVDixZvt5Jw4akru5dLFm+vtbNsBJOHDmwySsA2hDmf7/1x4kjBzwjrg1l/vdbf5w4cqCvmXLNhgLP6FyfnDhyYOGcNq444xjaWgsIaGstcO7xk/fstxaaGXtgMxRtq062+2trtbb3N+as25fV97Ke/657f8lpay1UbWDcqsuP4+ZE70y5e5PHp07yGDPUd9xTDxnF5bf9kls+/h4OO6il1s2xPviOw8zqyozDk0kpfrnJsxrVKycOM6srMyYkiWOtE0fdcuIws7oyptDMpIML/PI5J4565cRhZnVnxuGj3VVVx5w4zKzuvGPCGJ566XW27uipdVOsD04cZlZ3egfI17m7qi45cZhZ3XlHmwfI65kTh5nVnd8a3cLBI0d4nKNO+QVAM6s7kjhk5AiWrtrITQ88m/naK177ozJOHGZWd5at6uDJl16nZ3eyXlBnV/eeY1lsd3R2sXjpGgAnjzK4q8rM6s6S5ev3JI3B4rU/yufEYWZ1p1ZrcHjtj/JkmjgknSxpvaQNki7p4/g5klanXyskzUrLWyTdJ+kRSWslXVZ0zixJ/yVpjaQfShqdZQxmNvhqtQaH1/4oT2ZjHJKagKuA3wU2AvdLujUifllU7SngpIjYLOkU4FrgXcAO4L0RsVVSM/BzSXdExErgOuAzEfFTSR8DFgGfyyoOMxt8ixZMZ/HSNYO+5HFHZxezL+t7AL10MH3+UYdy77oX2dTZVdYgfSMNwGc5OH4csCEingSQdCNwOrAncUTEiqL6K4GJaXkAW9Py5vSrt8NzOvCzdPsuYDlOHGYNpfeH65Ll68v+wVzWU1X9lBcrdzD9hpXPVHxOowzAZ5k42oBni/Y3ktxN9Od84I7enfSO5UHgrcBVEfGL9NCjwGnAD4AzgUlVbLOZ1Yly1pCpRH9rkJxw5T10DNLYRu8AvBNH/9RHWZ+PSUiaT5I4TtxTMWIXMFtSK3CLpKMj4lHgY8A/SroUuBXY2c81LwQuBBg/fjzt7e1lN3zr1q0V1W8UeYw7jzFDPuPuL+bBShrFnzeY3/ss/q6zTBwbeePdwERgU2klSTNJxi1OiYiXS49HRKekduBk4NGIWAd8ID33bcCH+vrwiLiWZMyEuXPnRiWrndXz6mhZymPceYwZ8hl3fzG3rRy8Ow5IlsQdzO99Fn/XWT5VdT8wTdJUSSOAs0juEPaQNBlYCpwXEY8XlR+a3mkgqQC8H1iX7h+W/jkM+GvgmgxjMLMGt2jB9D3rnGetpXkYixZMH5TPylJmiSMieoCLSQavHwNuioi1ki6SdFFa7VJgHHC1pIclPZCWHw7cK2k1SQK6KyJuS4+dLelxkkSyCbg+qxjMrPEtnNPGFWccQ1trAQGthWbGHti81+221gLnHj+57HN6DZP49Hcf5oQr72HZqo5ahFsVmU45EhG3A7eXlF1TtH0BcEEf560G5vRzza8CX61uS80sz6o9EF/qloc28uffe4RtO5PHi4f6E1Z+c9zMLGN/f+fjlM6gMpSnOHHiMDPLWH9TmQzVKU6cOMzMMtbfVCZDdYoTJw4zs4z19eRWoblpyD5h5fU4zMwy1jsA/sUfr+O5V7czumU4nz/96CE5MA6+4zAzGxQL57TxX4vfx1G/dRCzJ48dskkDnDjMzAbVcVMP5sGnX6Fn1+5aN2WfOXGYmQ2i46YezOs7d7F205ZaN2WfOXGYmQ2i46YcDMB9T71S45bsOycOM7NBdNjoFqYeMpJfOHGYmVm5jptyMPc//Qq7S18nHyKcOMzMBlnTMHi1q5sj//L2ITnhoROHmdkgWraqg5sfShJFkEx4+OnvPsyUS340ZJKIE4eZ2SBasnw9O3re+Chub4dV76y59Z48nDjMzAbRQBMbDoVZc504zMwGUTkTG9b7rLlOHGZmg6icpWrrfdZcT3JoZjaIeueoWrJ8PR2dXYjfjHHA0Jg114nDzGyQFS9Vu2xVB3/7o1/y0tadjBs5gs+dOqPuJ0B0V5WZWQ0tnNPGXZ8+CYCLTjqy7pMGOHGYmdXc2JEjOGTUATzxwmu1bkpZnDjMzOrAtMNG8cQLW2vdjLI4cZiZ1YFp40ex4fmtRNT//FVOHGZmdWDa+IN4bUcPv96yvdZNGZATh5lZHZh22CgAnni+/rurnDjMzOrAnsQxBMY5nDjMzOrAuFEHcPDIEWwYAk9WZZo4JJ0sab2kDZIu6eP4OZJWp18rJM1Ky1sk3SfpEUlrJV1WdM5sSSslPSzpAUnHZRmDmdlgeetho/LdVSWpCbgKOAWYAZwtaUZJtaeAkyJiJnA5cG1avgN4b0TMAmYDJ0s6Pj32JeCyiJgNXJrum5kNeb2P5Nb7k1VZ3nEcB2yIiCcjYidwI3B6cYWIWBERm9PdlcDEtDwiojftNqdfvd/JAEan22OATdmFYGY2eKYdNopXu7p5ceuOWjdlr7Kcq6oNeLZofyPwrr3UPx+4o3cnvWN5EHgrcFVE/CI99ClguaS/J0l87+nrYpIuBC4EGD9+PO3t7WU3fOvWrRXVbxR5jDuPMUM+4x4KMW97eRcA37/zP5kxbu8z6JYri7izTBzqo6zP+y9J80kSx4l7KkbsAmZLagVukXR0RDwK/Anw6Yi4WdIfAP8KvP9NHxRxLWnX19y5c2PevHllN7y9vZ1K6jeKPMadx5ghn3EPhZifWfEU8Eu+dP92WgvNSNC5rZsJrQUWLZi+T/NYZRF3ll1VG4FJRfsT6aNbSdJM4Drg9Ih4ufR4RHQC7cDJadFHgaXp9vdIusTMzIa0Zas6uOKOdXv2O7u62byte8+65PW0pGyWieN+YJqkqZJGAGcBtxZXkDSZJAmcFxGPF5Ufmt5pIKlAckfR+x3dBJyUbr8XeCLDGMzMBsWS5evp6t7d7/F6WlI2s66qiOiRdDGwHGgCvh4RayVdlB6/huSpqHHA1ZIAeiJiLnA48M10nGMYcFNE3JZe+n8AX5U0HNhOOo5hZjaUlbNcbL0sKZvpQk4RcTtwe0nZNUXbFwAX9HHeamBOP9f8OXBsdVtqZlZbE1oLdAyQGOplSVm/OW5mVgcGWou8npaU9dKxZmZ1oHgt8k2dXYxJn6ravK2bQnMTV5xxTN2sDujEYWZWJ4rXIu/1Jzc8yNpNW+omaYC7qszM6trsSa0888o2Xq6jt8mdOMzM6tisSa0ArN74am0bUsSJw8ysjh3TNoZhgoef7ax1U/Zw4jAzq2MjDxjOtMMO4pGNnbVuyh5OHGZmdW7WpDE88mxn3Uy37sRhZlbnZk1qZfO2bp59pT7eHHfiMDOrc7MmtgLwcJ10V/k9DjOzOrf+11sA+MR3VnHpskf3TLc+pmjq9TEl07DPP+pQ7l33Ih2dXbStvGefp2XvixOHmVkdW7aqg79etnbPfmdX94DbHZ1d3LDymTfsL166BqAqycNdVWZmdSyZbn3Xfl+nmtOyO3GYmdWxak6lXq1rOXGYmdWxak6lXq1rOXGYmdWxgaZbL1c1p2V34jAzq2ML57RxxRnH0NZaQEBroZmxBzbvdbuttcC5x0+mLb3DaGstVHVadj9VZWZW5/qabr1c7e3tzJs3r6rt8R2HmZlVxInDzMwq4sRhZmYVceIwM7OKOHGYmVlFVC/zu2dJ0ovAryo45RDgpYyaU8/yGHceY4Z8xp3HmGH/4j4iIg4tLcxF4qiUpAciYm6t2zHY8hh3HmOGfMadx5ghm7jdVWVmZhVx4jAzs4o4cfTt2lo3oEbyGHceY4Z8xp3HmCGDuD3GYWZmFfEdh5mZVcSJw8zMKuLEUULSyZLWS9og6ZJatycLkiZJulfSY5LWSvpkWn6wpLskPZH+ObbWba02SU2SVkm6Ld3PQ8ytkr4vaV36d/7uRo9b0qfTf9uPSvqOpJZGjFnS1yW9IOnRorJ+45S0OP3Ztl7Sgn39XCeOIpKagKuAU4AZwNmSZtS2VZnoAf48It4OHA98PI3zEuDuiJgG3J3uN5pPAo8V7ech5q8CP46Io4BZJPE3bNyS2oBPAHMj4migCTiLxoz5G8DJJWV9xpn+Hz8LeEd6ztXpz7yKOXG80XHAhoh4MiJ2AjcCp9e4TVUXEc9FxEPp9mskP0jaSGL9Zlrtm8DCmjQwI5ImAh8CrisqbvSYRwO/A/wrQETsjIhOGjxukrWGCpKGAwcCm2jAmCPiZ8ArJcX9xXk6cGNE7IiIp4ANJD/zKubE8UZtwLNF+xvTsoYlaQowB/gFMD4inoMkuQCH1bBpWfgK8Flgd1FZo8f8FuBF4Pq0i+46SSNp4LgjogP4e+AZ4Dng1Yi4kwaOuUR/cVbt55sTxxupj7KGfV5Z0ijgZuBTEbGl1u3JkqRTgRci4sFat2WQDQfeCfxTRMwBXqcxumj6lfbpnw5MBSYAIyWdW9tW1YWq/Xxz4nijjcCkov2JJLe4DUdSM0nS+HZELE2Ln5d0eHr8cOCFWrUvAycAp0l6mqQL8r2SbqCxY4bk3/TGiPhFuv99kkTSyHG/H3gqIl6MiG5gKfAeGjvmYv3FWbWfb04cb3Q/ME3SVEkjSAaSbq1xm6pOkkj6vB+LiH8oOnQr8NF0+6PADwa7bVmJiMURMTEippD8vd4TEefSwDEDRMSvgWclTU+L3gf8ksaO+xngeEkHpv/W30cyjtfIMRfrL85bgbMkHSBpKjANuG9fPsBvjpeQ9EGSvvAm4OsR8Xe1bVH1SToR+A9gDb/p7/9LknGOm4DJJP/5zoyI0oG3IU/SPOAzEXGqpHE0eMySZpM8EDACeBL4Y5JfGhs2bkmXAR8heYJwFXABMIoGi1nSd4B5JFOnPw/8b2AZ/cQp6a+Aj5F8Xz4VEXfs0+c6cZiZWSXcVWVmZhVx4jAzs4o4cZiZWUWcOMzMrCJOHGZmVhEnDhuSJIWkLxftf0bS31Tp2t+Q9PvVuNYAn3NmOlvtvSXlU3pnO5U0O31EvFqf2SrpT4v2J0j6frWub/ngxGFD1Q7gDEmH1LohxSqcbfR84E8jYv5e6swGKkoc6cR+/WkF9iSOiNgUEZknSWssThw2VPWQrKX86dIDpXcMkramf86T9FNJN0l6XNKVks6RdJ+kNZKOLLrM+yX9R1rv1PT8JklLJN0vabWk/1l03Xsl/TvJS5Wl7Tk7vf6jkr6Yll0KnAhcI2lJXwGmsxd8HviIpIclfUTSyHQNhvvTSQtPT+v+kaTvSfohcKekUZLulvRQ+tm9szxfCRyZXm9Jyd1Ni6Tr0/qrJM0vuvZSST9WssbDl4q+H99I41oj6U1/F9aY9vabiVm9uwpY3fuDrEyzgLeTTEX9JHBdRBynZDGrPwM+ldabApwEHAncK+mtwB+SzLT625IOAP5T0p1p/eOAo9PpqveQNAH4InAssJnkh/rCiPi8pPeSvMH+QF8NjYidaYKZGxEXp9f7Asl0KR+T1ArcJ+kn6SnvBmZGxCvpXcfvRcSW9K5spaRbSSY4PDoiZqfXm1L0kR9PP/cYSUelbX1bemw2ySzKO4D1kr5GMutqW7rmBWl7LAd8x2FDVjqj77+RLNpTrvvT9Uh2AP8P6P3Bv4YkWfS6KSJ2R8QTJAnmKOADwB9KephkepZxJPP9ANxXmjRSvw20pxPu9QDfJlkfY199ALgkbUM70EIytQTAXUVTaAj4gqTVwE9Ips8eP8C1TwS+BRAR64BfAb2J4+6IeDUitpPMdXUEyfflLZK+JulkoKFnWLbf8B2HDXVfAR4Cri8q6yH9pSid5G5E0bEdRdu7i/Z388b/D6Vz8QTJD+M/i4jlxQfSua9e76d9fU1lvT8EfDgi1pe04V0lbTgHOBQ4NiK6lcwK3FLGtftT/H3bBQyPiM2SZgELSO5W/oBkHiRrcL7jsCEt/Q37JpKB5l5Pk3QNQbIuQ/M+XPpMScPScY+3AOuB5cCfKJmSHklvU7Io0t78AjhJ0iHpwPnZwE8raMdrwEFF+8uBP0sTIpLm9HPeGJL1R7rTsYoj+rlesZ+RJBzSLqrJJHH3Ke0CGxYRNwOfI5mu3XLAicMawZdJZgft9S8kP6zvA0p/Ey/XepIf8HcAF6VdNNeRdNM8lA4o/zMD3LWnK7AtBu4FHgEeiohKpvO+F5jROzgOXE6SCFenbbi8n/O+DcyV9ABJMliXtudlkrGZR/sYlL8aaJK0Bvgu8Edpl15/2oD2tNvsG2mclgOeHdfMzCriOw4zM6uIE4eZmVXEicPMzCrixGFmZhVx4jAzs4o4cZiZWUWcOMzMrCL/H/v2o7y3NbRyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perform feature selection\n",
    "start_time = time.time()\n",
    "fmdl  = jfs(X_train, y_train, opts)\n",
    "\n",
    "sf    = fmdl['sf']\n",
    "\n",
    "# model with selected features\n",
    "num_train = np.size(xtrain, 0)\n",
    "num_valid = np.size(xtest, 0)\n",
    "x_train   = xtrain[:, sf]\n",
    "y_train   = ytrain.reshape(num_train)  # Solve bug\n",
    "x_valid   = xtest[:, sf]\n",
    "y_valid   = ytest.reshape(num_valid)  # Solve bug\n",
    "\n",
    "mdl2       = LogisticRegression()\n",
    "mdl2.fit(x_train, y_train)\n",
    "\n",
    "# accuracy\n",
    "y_pred    = mdl2.predict(x_valid)\n",
    "RMSE       = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"RMSE:\", RMSE)\n",
    "\n",
    "# number of selected features\n",
    "num_feat = fmdl['nf']\n",
    "print(\"Feature Size:\", num_feat)\n",
    "\n",
    "# plot convergence\n",
    "curve   = fmdl['c']\n",
    "curve   = curve.reshape(np.size(curve,1))\n",
    "x       = np.arange(0, opts['T'], 1.0) + 1.0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, curve, 'o-')\n",
    "ax.set_xlabel('Number of Iterations')\n",
    "ax.set_ylabel('Fitness')\n",
    "ax.set_title('PSO')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "088e9630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    4,    5, ..., 2392, 2394, 2396])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmdl['sf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fc4b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test.drop(['default.payment.next.month'], axis=1).iloc[:,fmdl['sf']]\n",
    "new_data = df.drop(['Swarm_Behaviour'], axis=1)\n",
    "new_data = df.iloc[:,fmdl['sf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8462dfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>xA1</th>\n",
       "      <th>yA1</th>\n",
       "      <th>xS1</th>\n",
       "      <th>nS1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>xVel2</th>\n",
       "      <th>xA2</th>\n",
       "      <th>nS2</th>\n",
       "      <th>...</th>\n",
       "      <th>x199</th>\n",
       "      <th>y199</th>\n",
       "      <th>xVel199</th>\n",
       "      <th>yVel199</th>\n",
       "      <th>yS199</th>\n",
       "      <th>nAC199</th>\n",
       "      <th>nS199</th>\n",
       "      <th>xA200</th>\n",
       "      <th>xS200</th>\n",
       "      <th>xC200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.567249</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375462</td>\n",
       "      <td>0.271498</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824240</td>\n",
       "      <td>0.129155</td>\n",
       "      <td>0.840852</td>\n",
       "      <td>0.149560</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.467991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542042</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452232</td>\n",
       "      <td>0.330157</td>\n",
       "      <td>0.748686</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903323</td>\n",
       "      <td>0.619802</td>\n",
       "      <td>0.286967</td>\n",
       "      <td>0.427315</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.467991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389190</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066272</td>\n",
       "      <td>0.596891</td>\n",
       "      <td>0.870043</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542563</td>\n",
       "      <td>0.088764</td>\n",
       "      <td>0.890560</td>\n",
       "      <td>0.551320</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.443709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041595</td>\n",
       "      <td>0.453552</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459562</td>\n",
       "      <td>0.792044</td>\n",
       "      <td>0.499761</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461169</td>\n",
       "      <td>0.615990</td>\n",
       "      <td>0.405180</td>\n",
       "      <td>0.881022</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.100719</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.467991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.955307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979695</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224034</td>\n",
       "      <td>0.143699</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338665</td>\n",
       "      <td>0.187239</td>\n",
       "      <td>0.989557</td>\n",
       "      <td>0.196062</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.215827</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.467991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23304</th>\n",
       "      <td>0.620464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010146</td>\n",
       "      <td>0.035553</td>\n",
       "      <td>0.386049</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150347</td>\n",
       "      <td>0.191827</td>\n",
       "      <td>0.287385</td>\n",
       "      <td>0.049434</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.148784</td>\n",
       "      <td>0.467991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23305</th>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.218274</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644009</td>\n",
       "      <td>0.713554</td>\n",
       "      <td>0.526995</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431313</td>\n",
       "      <td>0.611402</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>0.354396</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.438144</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.472406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23306</th>\n",
       "      <td>0.101663</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.363615</td>\n",
       "      <td>0.049607</td>\n",
       "      <td>0.532728</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226882</td>\n",
       "      <td>0.478017</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.101382</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.330935</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.467991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23307</th>\n",
       "      <td>0.832132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037359</td>\n",
       "      <td>0.151441</td>\n",
       "      <td>0.707119</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481962</td>\n",
       "      <td>0.359228</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.858400</td>\n",
       "      <td>0.975275</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.467991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23308</th>\n",
       "      <td>0.033907</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>0.487310</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041874</td>\n",
       "      <td>0.130002</td>\n",
       "      <td>0.448161</td>\n",
       "      <td>0.595628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.083701</td>\n",
       "      <td>0.628237</td>\n",
       "      <td>0.284876</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.448454</td>\n",
       "      <td>0.682403</td>\n",
       "      <td>0.467991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23309 rows × 1170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y1       xA1       yA1       xS1       nS1        x2        y2  \\\n",
       "0      0.567249  0.546448  0.497462  0.529915  0.000000  0.375462  0.271498   \n",
       "1      0.542042  0.546448  0.497462  0.529915  0.000000  0.452232  0.330157   \n",
       "2      0.389190  0.546448  0.497462  0.529915  0.000000  0.066272  0.596891   \n",
       "3      0.041595  0.453552  0.994924  0.529915  0.000000  0.459562  0.792044   \n",
       "4      0.955307  0.000000  0.979695  0.529915  0.000000  0.224034  0.143699   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23304  0.620464  0.000000  0.497462  0.529915  0.000000  0.010146  0.035553   \n",
       "23305  0.446755  0.508197  0.218274  0.529915  0.000000  0.644009  0.713554   \n",
       "23306  0.101663  0.546448  0.497462  0.529915  0.034483  0.363615  0.049607   \n",
       "23307  0.832132  0.000000  0.000000  0.529915  0.000000  0.037359  0.151441   \n",
       "23308  0.033907  0.601093  0.487310  0.529915  0.000000  0.041874  0.130002   \n",
       "\n",
       "          xVel2       xA2       nS2  ...      x199      y199   xVel199  \\\n",
       "0      0.535117  0.540984  0.000000  ...  0.824240  0.129155  0.840852   \n",
       "1      0.748686  0.540984  0.000000  ...  0.903323  0.619802  0.286967   \n",
       "2      0.870043  0.540984  0.000000  ...  0.542563  0.088764  0.890560   \n",
       "3      0.499761  0.491803  0.000000  ...  0.461169  0.615990  0.405180   \n",
       "4      0.037267  0.005464  0.000000  ...  0.338665  0.187239  0.989557   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "23304  0.386049  0.540984  0.000000  ...  0.150347  0.191827  0.287385   \n",
       "23305  0.526995  0.491803  0.015873  ...  0.431313  0.611402  0.650794   \n",
       "23306  0.532728  0.540984  0.000000  ...  0.226882  0.478017  0.903509   \n",
       "23307  0.707119  0.005464  0.000000  ...  0.481962  0.359228  0.214286   \n",
       "23308  0.448161  0.595628  0.000000  ...  0.070671  0.083701  0.628237   \n",
       "\n",
       "        yVel199     yS199    nAC199  nS199     xA200     xS200     xC200  \n",
       "0      0.149560  0.538462  0.251799   0.04  0.515464  0.509299  0.467991  \n",
       "1      0.427315  0.538462  0.035971   0.00  0.515464  0.509299  0.467991  \n",
       "2      0.551320  0.538462  0.043165   0.00  0.515464  0.509299  0.443709  \n",
       "3      0.881022  0.538462  0.100719   0.00  0.381443  0.509299  0.467991  \n",
       "4      0.196062  0.538462  0.215827   0.04  0.005155  0.841202  0.467991  \n",
       "...         ...       ...       ...    ...       ...       ...       ...  \n",
       "23304  0.049434  0.538462  0.064748   0.00  0.005155  0.148784  0.467991  \n",
       "23305  0.073733  0.354396  0.834532   0.04  0.438144  0.509299  0.472406  \n",
       "23306  0.101382  0.538462  0.330935   0.00  0.515464  0.509299  0.467991  \n",
       "23307  0.858400  0.975275  0.057554   0.04  0.005155  0.509299  0.467991  \n",
       "23308  0.284876  0.538462  0.000000   0.00  0.448454  0.682403  0.467991  \n",
       "\n",
       "[23309 rows x 1170 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e26c1",
   "metadata": {},
   "source": [
    "## Classification after Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4521e96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (23309, 1170)\n",
      "Shape of y_train: (23309,)\n"
     ]
    }
   ],
   "source": [
    "#feature variables\n",
    "X = new_data.values\n",
    "\n",
    "#target variable\n",
    "y = df['Swarm_Behaviour'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=23)\n",
    "\n",
    "print(\"Shape of X_train:\", X.shape)\n",
    "print(\"Shape of y_train:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55145da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models1['Logistic Regression'] = LogisticRegression(solver='lbfgs', max_iter=2000)\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC\n",
    "models1['Support Vector Machines'] = SVC(kernel='linear')\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models1['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models1['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models1['K-Nearest Neighbor'] = KNeighborsClassifier()\n",
    "\n",
    "# Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "models1['Neural Networks'] = MLPClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ac16f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy1 = {}\n",
    "\n",
    "for key in models1.keys():\n",
    "    \n",
    "    # Fit the classifier\n",
    "    models1[key].fit(X_train, y_train)\n",
    "    \n",
    "#     # Make predictions\n",
    "    predictions1 = models1[key].predict(X_test)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "    accuracy1[key] = accuracy_score(predictions1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61c1ec66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.889747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.888460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.872015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.871443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.891177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy\n",
       "Logistic Regression      0.889747\n",
       "Support Vector Machines  0.888460\n",
       "Decision Trees           0.872015\n",
       "Random Forest            0.871443\n",
       "K-Nearest Neighbor       0.888889\n",
       "Neural Networks          0.891177"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model1 = pd.DataFrame(index=models1.keys(), columns=['Accuracy'])\n",
    "df_model1['Accuracy'] = accuracy1.values()\n",
    "\n",
    "df_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87e94b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h3 style=\"text-align: center;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc0d5acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:center\"><td style=\"vertical-align:top\"><h3 style=\"text-align: center;\">Classification without PSO</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.880023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.877020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.872015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.870013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.888460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.894323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th><th style=\"text-align:center\"><td style=\"vertical-align:top\"><h3 style=\"text-align: center;\">Classification with PSO</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.889747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.888460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.872015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.871443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.891177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_side_by_side(df_model,df_model1, titles=['Classification without PSO','Classification with PSO'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
